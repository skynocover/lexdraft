import { DurableObject } from "cloudflare:workers";
import { nanoid } from "nanoid";
import { eq, asc } from "drizzle-orm";
import { getDB } from "../db";
import { messages } from "../db/schema";
import {
  callAIStreaming,
  type ChatMessage,
  type ToolCall,
  type AIEnv,
} from "../agent/aiClient";
import { TOOL_DEFINITIONS, executeTool } from "../agent/tools";
import { parseOpenAIStream, type OpenAIChunk } from "../agent/sseParser";
import type { SSEEvent } from "../../shared/types";

const MAX_ROUNDS = 30;

const SYSTEM_PROMPT = `ä½ æ˜¯ LexDraft AI åŠ©ç†ï¼Œä¸€ä½å°ˆæ¥­çš„å°ç£æ³•å¾‹åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯å”åŠ©å¾‹å¸«åˆ†ææ¡ˆä»¶å·å®—ã€æ•´ç†çˆ­é»ã€æ’°å¯«æ³•å¾‹æ›¸ç‹€ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
- list_filesï¼šåˆ—å‡ºæ¡ˆä»¶æ‰€æœ‰æª”æ¡ˆ
- read_fileï¼šè®€å–æŒ‡å®šæª”æ¡ˆçš„å…¨æ–‡
- create_briefï¼šå»ºç«‹æ–°æ›¸ç‹€ï¼ˆå–å¾— brief_idï¼‰
- analyze_disputesï¼šåˆ†ææ¡ˆä»¶çˆ­é»ï¼ˆè‡ªå‹•è¼‰å…¥æ‰€æœ‰æª”æ¡ˆæ‘˜è¦é€²è¡Œåˆ†æï¼‰
- calculate_damagesï¼šè¨ˆç®—å„é …è«‹æ±‚é‡‘é¡æ˜ç´°ï¼ˆè‡ªå‹•è¼‰å…¥æ‰€æœ‰æª”æ¡ˆæ‘˜è¦åˆ†æé‡‘é¡ï¼‰
- write_brief_sectionï¼šæ’°å¯«æ›¸ç‹€æ®µè½ï¼ˆä½¿ç”¨å¼•ç”¨ç³»çµ±ï¼Œå¾ä¾†æºæ–‡ä»¶ä¸­æå–ç²¾ç¢ºå¼•ç”¨ï¼‰
- search_lawï¼šæœå°‹æ³•è¦æ¢æ–‡ï¼ˆæ”¯æ´æ³•è¦åç¨±ã€æ¢è™Ÿã€æ³•å¾‹æ¦‚å¿µæœå°‹ï¼Œçµæœè‡ªå‹•å¯«å…¥æ³•æ¢å¼•ç”¨åˆ—è¡¨ï¼‰
- generate_timelineï¼šåˆ†ææ™‚é–“è»¸ï¼ˆè‡ªå‹•è¼‰å…¥æ‰€æœ‰æª”æ¡ˆæ‘˜è¦ï¼Œç”¢ç”Ÿæ™‚é–“è»¸äº‹ä»¶åˆ—è¡¨ï¼‰

å·¥ä½œæµç¨‹ï¼š
1. ç•¶å¾‹å¸«è¦æ±‚åˆ†ææ¡ˆä»¶æ™‚ï¼Œå…ˆç”¨ list_files æŸ¥çœ‹æœ‰å“ªäº›æ–‡ä»¶
2. æ ¹æ“šéœ€è¦ç”¨ read_file è®€å–ç›¸é—œæ–‡ä»¶
3. ç¶œåˆåˆ†æå¾Œæä¾›å°ˆæ¥­çš„æ³•å¾‹æ„è¦‹

æ³•æ¢æœå°‹ä½¿ç”¨æ™‚æ©Ÿï¼ˆä½¿ç”¨ search_law å·¥å…·ï¼‰ï¼š
- ç•¶ä½¿ç”¨è€…æ˜ç¢ºè¦æ±‚æœå°‹æ³•æ¢æ™‚ï¼ˆå¦‚ã€ŒæŸ¥è©¢æ°‘æ³•ç¬¬184æ¢ã€ã€Œæœå°‹ä¾µæ¬Šè¡Œç‚ºç›¸é—œæ³•æ¢ã€ã€Œæ‰¾æå®³è³ å„Ÿçš„è¦å®šã€ï¼‰
- ç•¶ä½¿ç”¨è€…å•åˆ°æ³•å¾‹å•é¡Œæˆ–æ³•è¦ä¾æ“šæ™‚ï¼Œä¸»å‹•æœå°‹ç›¸é—œæ³•æ¢
- æ’°å¯«æ›¸ç‹€æ™‚ï¼Œé‡å°æ¯å€‹çˆ­é»æœå°‹ç›¸é—œæ³•æ¢ä»¥å¼·åŒ–è«–è¿°
- search_law æ”¯æ´ï¼šæ³•è¦åç¨±ï¼ˆã€Œæ°‘æ³•ã€ï¼‰ã€ç‰¹å®šæ¢è™Ÿï¼ˆã€Œæ°‘æ³•ç¬¬184æ¢ã€ï¼‰ã€æ³•å¾‹æ¦‚å¿µï¼ˆã€Œæå®³è³ å„Ÿã€ï¼‰ç­‰æœå°‹æ–¹å¼
- æœå°‹çµæœæœƒè‡ªå‹•é¡¯ç¤ºåœ¨å³å´ã€Œæ³•æ¢å¼•ç”¨ã€é¢æ¿ä¸­

æ™‚é–“è»¸åˆ†æä½¿ç”¨æ™‚æ©Ÿï¼ˆä½¿ç”¨ generate_timeline å·¥å…·ï¼‰ï¼š
- ç•¶ä½¿ç”¨è€…è¦æ±‚ã€Œåˆ†ææ™‚é–“è»¸ã€ã€Œæ•´ç†äº‹ä»¶ç¶“éã€ã€Œåˆ—å‡ºæ™‚é–“é †åºã€æ™‚
- çµæœæœƒé¡¯ç¤ºåœ¨åº•éƒ¨ã€Œæ™‚é–“è»¸ã€åˆ†é ä¸­

æ›¸ç‹€æ’°å¯«æµç¨‹ï¼ˆæ”¶åˆ°æ’°å¯«æ›¸ç‹€æŒ‡ä»¤å¾Œï¼Œç›´æ¥åŸ·è¡Œï¼Œä¸è¦åå•ä½¿ç”¨è€…ï¼‰ï¼š
1. å…ˆç”¨ list_files ç¢ºèªå¯ç”¨çš„ä¾†æºæª”æ¡ˆ
2. ç”¨ read_file è®€å–é—œéµæª”æ¡ˆå…§å®¹
3. ç”¨ analyze_disputes åˆ†æçˆ­é»ï¼ˆå¦‚æœå°šæœªåˆ†æï¼‰
4. ç”¨ search_law æœå°‹æ¯å€‹çˆ­é»ç›¸é—œçš„æ³•æ¢ï¼ˆåŠ å¼·æ›¸ç‹€æ³•å¾‹ä¾æ“šï¼‰
5. ç”¨ create_brief å»ºç«‹æ–°æ›¸ç‹€ â€” è‡ªè¡Œæ ¹æ“šæ¡ˆä»¶æ€§è³ªæ±ºå®š brief_type å’Œ titleï¼ˆä¾‹å¦‚ã€Œæ°‘äº‹æº–å‚™æ›¸ç‹€ã€ã€Œæ°‘äº‹ç­”è¾¯ç‹€ã€ç­‰ï¼‰ï¼Œä¸éœ€è¦è©¢å•ä½¿ç”¨è€…
6. é€æ®µä½¿ç”¨ write_brief_section æ’°å¯«æ›¸ç‹€ï¼Œæ¯æ¬¡æ’°å¯«ä¸€å€‹æ®µè½
7. æ›¸ç‹€çµæ§‹åƒè€ƒæ¨¡æ¿ï¼š
   - å£¹ã€å‰è¨€ï¼ˆæ¡ˆä»¶èƒŒæ™¯ã€æå‡ºæœ¬ç‹€ç›®çš„ï¼‰
   - è²³ã€å°±è¢«å‘Šå„é …æŠ—è¾¯ä¹‹åé§ï¼ˆä¾çˆ­é»é€ä¸€åé§ï¼‰
   - åƒã€è«‹æ±‚é‡‘é¡ä¹‹è¨ˆç®—ï¼ˆå¦‚é©ç”¨ï¼‰
   - è‚†ã€çµè«–

é‡è¦ï¼šç•¶ä½¿ç”¨è€…è¦æ±‚æ’°å¯«æ›¸ç‹€æ™‚ï¼Œä½ æ‡‰è©²ä¸»å‹•å®Œæˆæ•´å€‹æµç¨‹ï¼Œä¸è¦ä¸­é€”åœä¸‹ä¾†è©¢å•æ›¸ç‹€é¡å‹æˆ–æ¨™é¡Œã€‚æ ¹æ“šæ¡ˆä»¶å·å®—è‡ªå‹•åˆ¤æ–·æœ€é©åˆçš„æ›¸ç‹€é¡å‹å’Œæ¨™é¡Œã€‚

å¼•ç”¨è¦å‰‡ï¼š
- write_brief_section æœƒè‡ªå‹•ä½¿ç”¨ Claude Citations API å¾ä¾†æºæ–‡ä»¶æå–å¼•ç”¨
- æ¯å€‹æ®µè½éƒ½æ‡‰æä¾› relevant_file_idsï¼Œç¢ºä¿å¼•ç”¨æœ‰æ“šå¯æŸ¥
- å¦‚æœ‰é—œè¯çˆ­é»ï¼Œæ‡‰æä¾› dispute_id

å›è¦†è¦å‰‡ï¼š
- ä¸€å¾‹ä½¿ç”¨ç¹é«”ä¸­æ–‡
- çµ•å°ä¸è¦ä½¿ç”¨ emoji æˆ–ç‰¹æ®Šç¬¦è™Ÿï¼ˆå¦‚ âœ…âŒğŸ”·ğŸ“„ ç­‰ï¼‰ï¼Œåªç”¨ç´”æ–‡å­—å’Œæ¨™é»ç¬¦è™Ÿ
- å¼•ç”¨æ–‡ä»¶å…§å®¹æ™‚æ¨™æ˜å‡ºè™•ï¼ˆæª”æ¡ˆåç¨±ï¼‰
- åˆ†æè¦æœ‰çµæ§‹ã€æ¢ç†åˆ†æ˜
- å¦‚æœè³‡è¨Šä¸è¶³ï¼Œä¸»å‹•èªªæ˜éœ€è¦å“ªäº›é¡å¤–è³‡æ–™
- åˆ—èˆ‰é …ç›®æ™‚ä½¿ç”¨é “è™Ÿï¼ˆã€ï¼‰æˆ–æ•¸å­—ç·¨è™Ÿï¼Œä¸è¦ç”¨ emoji æˆ–ç‰¹æ®Šç¬¦è™Ÿ
- æ’°å¯«æ›¸ç‹€å®Œæˆå¾Œï¼Œåªéœ€ç°¡çŸ­å›è¦†ã€Œå·²å®Œæˆæ›¸ç‹€æ’°å¯«ï¼Œå…± N å€‹æ®µè½ã€å³å¯ï¼Œçµ•å°ä¸è¦åœ¨èŠå¤©ä¸­é‡è¤‡æ›¸ç‹€çš„å…§å®¹ï¼Œå› ç‚ºæ›¸ç‹€å·²ç¶“å³æ™‚é¡¯ç¤ºåœ¨å³å´ç·¨è¼¯å™¨ä¸­`;

interface Env {
  DB: D1Database;
  CF_ACCOUNT_ID: string;
  CF_GATEWAY_ID: string;
  CF_AIG_TOKEN: string;
  MONGO_URL: string;
}

export class AgentDO extends DurableObject<Env> {
  private abortController: AbortController | null = null;

  async fetch(request: Request): Promise<Response> {
    const url = new URL(request.url);

    if (request.method === "POST" && url.pathname === "/chat") {
      return this.handleChat(request);
    }
    if (request.method === "POST" && url.pathname === "/cancel") {
      return this.handleCancel();
    }

    return new Response("Not found", { status: 404 });
  }

  private handleCancel(): Response {
    if (this.abortController) {
      this.abortController.abort();
      this.abortController = null;
    }
    return new Response(JSON.stringify({ ok: true }), {
      headers: { "Content-Type": "application/json" },
    });
  }

  private async handleChat(request: Request): Promise<Response> {
    const { message, caseId } = (await request.json()) as {
      message: string;
      caseId: string;
    };

    this.abortController = new AbortController();
    const signal = this.abortController.signal;

    const { readable, writable } = new TransformStream();
    const writer = writable.getWriter();
    const encoder = new TextEncoder();

    const sendSSE = async (event: SSEEvent) => {
      try {
        await writer.write(
          encoder.encode(`data: ${JSON.stringify(event)}\n\n`),
        );
      } catch {
        // Writer closed, ignore
      }
    };

    // Run agent loop asynchronously
    this.runAgentLoop(caseId, message, signal, sendSSE, writer).catch(
      async (err) => {
        console.error("Agent loop error:", err);
        await sendSSE({
          type: "error",
          message: err instanceof Error ? err.message : "Unknown error",
        });
        await sendSSE({ type: "done" });
        try {
          await writer.close();
        } catch {
          /* ignore */
        }
      },
    );

    return new Response(readable, {
      headers: {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        Connection: "keep-alive",
      },
    });
  }

  private async runAgentLoop(
    caseId: string,
    userMessage: string,
    signal: AbortSignal,
    sendSSE: (event: SSEEvent) => Promise<void>,
    writer: WritableStreamDefaultWriter,
  ) {
    const db = getDB(this.env.DB);
    const aiEnv: AIEnv = {
      CF_ACCOUNT_ID: this.env.CF_ACCOUNT_ID,
      CF_GATEWAY_ID: this.env.CF_GATEWAY_ID,
      CF_AIG_TOKEN: this.env.CF_AIG_TOKEN,
    };

    // 1. Save user message
    const userMsgId = nanoid();
    await db.insert(messages).values({
      id: userMsgId,
      case_id: caseId,
      role: "user",
      content: userMessage,
      created_at: new Date().toISOString(),
    });

    // 2. Load conversation history
    const history = await db
      .select()
      .from(messages)
      .where(eq(messages.case_id, caseId))
      .orderBy(asc(messages.created_at));

    // 3. Build OpenAI messages format
    const chatMessages: ChatMessage[] = [
      { role: "system", content: SYSTEM_PROMPT },
    ];

    for (const msg of history) {
      if (msg.role === "user") {
        chatMessages.push({ role: "user", content: msg.content });
      } else if (msg.role === "assistant") {
        const meta = msg.metadata ? JSON.parse(msg.metadata) : null;
        if (meta?.tool_calls) {
          chatMessages.push({
            role: "assistant",
            content: msg.content || "",
            tool_calls: meta.tool_calls,
          });
        } else {
          chatMessages.push({ role: "assistant", content: msg.content });
        }
      } else if (msg.role === "tool_result") {
        const meta = msg.metadata ? JSON.parse(msg.metadata) : null;
        chatMessages.push({
          role: "tool",
          content: msg.content,
          tool_call_id: meta?.tool_call_id || "",
        });
      }
      // Skip tool_call records (they're part of assistant messages)
    }

    let totalPromptTokens = 0;
    let totalCompletionTokens = 0;

    // Agent loop
    for (let round = 0; round < MAX_ROUNDS; round++) {
      if (signal.aborted) {
        await sendSSE({ type: "error", message: "å·²å–æ¶ˆ" });
        break;
      }

      await sendSSE({
        type: "progress",
        current: round + 1,
        total: MAX_ROUNDS,
      });

      // Call AI Gateway (streaming)
      const response = await callAIStreaming(aiEnv, {
        messages: chatMessages,
        tools: TOOL_DEFINITIONS,
        signal,
      });

      // Parse streaming response
      const assistantMsgId = nanoid();
      await sendSSE({
        type: "message_start",
        message_id: assistantMsgId,
        role: "assistant",
      });

      let fullContent = "";
      const toolCalls: ToolCall[] = [];
      const toolCallBuffers: Map<
        number,
        { id: string; name: string; args: string }
      > = new Map();

      await parseOpenAIStream(response, async (chunk: OpenAIChunk) => {
        if (signal.aborted) return;

        // Track usage from final chunk
        if (chunk.usage) {
          totalPromptTokens += chunk.usage.prompt_tokens || 0;
          totalCompletionTokens += chunk.usage.completion_tokens || 0;
        }

        const delta = chunk.choices?.[0]?.delta;
        if (!delta) return;

        // Text content
        if (delta.content) {
          fullContent += delta.content;
          await sendSSE({ type: "text_delta", delta: delta.content });
        }

        // Tool calls (streamed incrementally)
        if (delta.tool_calls) {
          for (const tc of delta.tool_calls) {
            const idx = tc.index;
            if (!toolCallBuffers.has(idx)) {
              toolCallBuffers.set(idx, { id: tc.id || "", name: "", args: "" });
            }
            const buf = toolCallBuffers.get(idx)!;
            if (tc.id) buf.id = tc.id;
            if (tc.function?.name) buf.name += tc.function.name;
            if (tc.function?.arguments) buf.args += tc.function.arguments;
          }
        }
      });

      await sendSSE({ type: "message_end", message_id: assistantMsgId });

      // Assemble complete tool calls
      for (const [, buf] of toolCallBuffers) {
        toolCalls.push({
          id: buf.id,
          type: "function",
          function: { name: buf.name, arguments: buf.args },
        });
      }

      // Emit usage
      const totalTokens = totalPromptTokens + totalCompletionTokens;
      // Gemini 2.5 Flash pricing: ~$0.15/1M input, ~$0.60/1M output (approximate)
      const costUsd =
        (totalPromptTokens * 0.15 + totalCompletionTokens * 0.6) / 1_000_000;
      const costNtd = Math.round(costUsd * 32 * 10000) / 10000;
      await sendSSE({
        type: "usage",
        prompt_tokens: totalPromptTokens,
        completion_tokens: totalCompletionTokens,
        total_tokens: totalTokens,
        estimated_cost_ntd: costNtd,
      });

      if (toolCalls.length > 0) {
        // Save assistant message with tool_calls metadata
        await db.insert(messages).values({
          id: assistantMsgId,
          case_id: caseId,
          role: "assistant",
          content: fullContent || "",
          metadata: JSON.stringify({ tool_calls: toolCalls }),
          created_at: new Date().toISOString(),
        });

        // Add assistant message to conversation
        chatMessages.push({
          role: "assistant",
          content: fullContent || "",
          tool_calls: toolCalls,
        });

        // Execute each tool call
        for (const tc of toolCalls) {
          if (signal.aborted) break;

          let args: Record<string, unknown> = {};
          try {
            args = JSON.parse(tc.function.arguments);
          } catch {
            /* empty args */
          }

          const toolMsgId = nanoid();
          await sendSSE({
            type: "tool_call_start",
            message_id: toolMsgId,
            tool_name: tc.function.name,
            tool_args: args,
          });

          // Save tool_call record
          await db.insert(messages).values({
            id: toolMsgId,
            case_id: caseId,
            role: "tool_call",
            content: tc.function.name,
            metadata: JSON.stringify({ tool_call_id: tc.id, args }),
            created_at: new Date().toISOString(),
          });

          // Execute tool
          const { result, success } = await executeTool(
            tc.function.name,
            args,
            caseId,
            this.env.DB,
            {
              sendSSE,
              aiEnv,
              mongoUrl: this.env.MONGO_URL,
            },
          );

          // Truncate summary for SSE display
          const resultSummary =
            result.length > 200 ? result.slice(0, 200) + "..." : result;

          await sendSSE({
            type: "tool_result",
            message_id: toolMsgId,
            tool_name: tc.function.name,
            result_summary: resultSummary,
            success,
          });

          // Save tool_result record
          const toolResultId = nanoid();
          await db.insert(messages).values({
            id: toolResultId,
            case_id: caseId,
            role: "tool_result",
            content: result,
            metadata: JSON.stringify({
              tool_call_id: tc.id,
              tool_name: tc.function.name,
              success,
            }),
            created_at: new Date().toISOString(),
          });

          // Add tool result to conversation
          chatMessages.push({
            role: "tool",
            content: result,
            tool_call_id: tc.id,
          });
        }

        // Continue loop â€” AI will process tool results
        continue;
      }

      // No tool calls â†’ save final assistant message and done
      await db.insert(messages).values({
        id: assistantMsgId,
        case_id: caseId,
        role: "assistant",
        content: fullContent,
        created_at: new Date().toISOString(),
      });

      break;
    }

    await sendSSE({ type: "done" });
    try {
      await writer.close();
    } catch {
      /* ignore */
    }
    this.abortController = null;
  }
}
