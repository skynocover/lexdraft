import { DurableObject } from 'cloudflare:workers';
import { nanoid } from 'nanoid';
import { eq, asc } from 'drizzle-orm';
import { getDB } from '../db';
import { messages, cases } from '../db/schema';
import {
  callAI,
  callAIStreaming,
  type ChatMessage,
  type ToolCall,
  type AIEnv,
} from '../agent/aiClient';
import { TOOL_DEFINITIONS, executeTool } from '../agent/tools';
import { parseOpenAIStream, type OpenAIChunk } from '../agent/sseParser';
import { parseLLMJsonArray } from '../agent/toolHelpers';

const VALID_TOOL_NAMES = new Set(TOOL_DEFINITIONS.map((t) => t.function.name));
import type { SSEEvent } from '../../shared/types';

const MAX_ROUNDS = 30;

const SUGGEST_PROMPT = `ä½ æ˜¯æ³•å¾‹åŠ©ç†çš„å»ºè­°ç³»çµ±ã€‚æ ¹æ“šå°è©±ä¸Šä¸‹æ–‡ï¼Œç”¢ç”Ÿ 2-3 å€‹ä½¿ç”¨è€…å¯èƒ½æƒ³åšçš„ä¸‹ä¸€æ­¥æ“ä½œã€‚

ç›´æ¥è¼¸å‡º JSON arrayï¼Œä¸è¦ç”¨ markdown code block åŒ…è£¹ï¼Œä¸è¦åŠ ä»»ä½•å…¶ä»–æ–‡å­—ã€‚
æ ¼å¼ç¯„ä¾‹ï¼š[{"label":"åˆ†æçˆ­é»","prompt":"è«‹åˆ†ææ¡ˆä»¶çˆ­é»"},{"label":"æœå°‹æ³•æ¢","prompt":"è«‹æœå°‹ç›¸é—œæ³•æ¢"}]

è¦å‰‡ï¼š
- label æœ€å¤š 4 å€‹ä¸­æ–‡å­—
- prompt æ˜¯å®Œæ•´çš„ä½¿ç”¨è€…æŒ‡ä»¤
- æ ¹æ“šå°è©±é€²åº¦å»ºè­°åˆç†çš„ä¸‹ä¸€æ­¥
- ä¸è¦å»ºè­°ä½¿ç”¨è€…å·²ç¶“åšéçš„æ“ä½œ
- æœ€å¤š 3 å€‹å»ºè­°`;

const SYSTEM_PROMPT = `ä½ æ˜¯ LexDraft AI åŠ©ç†ï¼Œä¸€ä½å°ˆæ¥­çš„å°ç£æ³•å¾‹åˆ†æåŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯å”åŠ©å¾‹å¸«åˆ†ææ¡ˆä»¶å·å®—ã€æ•´ç†çˆ­é»ã€æ’°å¯«æ³•å¾‹æ›¸ç‹€ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
- list_filesï¼šåˆ—å‡ºæ¡ˆä»¶æ‰€æœ‰æª”æ¡ˆ
- read_fileï¼šè®€å–æŒ‡å®šæª”æ¡ˆçš„å…¨æ–‡
- create_briefï¼šå»ºç«‹æ–°æ›¸ç‹€ï¼ˆå–å¾— brief_idï¼‰
- write_full_briefï¼šæ’°å¯«å®Œæ•´æ›¸ç‹€ï¼ˆä¸€æ¬¡å®Œæˆæ•´ä»½æ›¸ç‹€ï¼Œå…§éƒ¨è‡ªå‹•è¼‰å…¥è³‡æ–™ã€åˆ†æçˆ­é»ã€è¦åŠƒçµæ§‹ã€æœå°‹æ³•æ¢ã€é€æ®µæ’°å¯«ï¼‰
- write_brief_sectionï¼šæ’°å¯«æˆ–ä¿®æ”¹æ›¸ç‹€çš„å–®ä¸€æ®µè½ï¼ˆä½¿ç”¨å¼•ç”¨ç³»çµ±ï¼Œå¾ä¾†æºæ–‡ä»¶ä¸­æå–ç²¾ç¢ºå¼•ç”¨ï¼‰ã€‚æä¾› paragraph_id æ™‚æœƒä¿®æ”¹æ—¢æœ‰æ®µè½ï¼Œä¸æä¾›å‰‡æ–°å¢æ®µè½ã€‚
- analyze_disputesï¼šåˆ†ææ¡ˆä»¶çˆ­é»ï¼ˆè‡ªå‹•è¼‰å…¥æ‰€æœ‰æª”æ¡ˆæ‘˜è¦é€²è¡Œåˆ†æï¼‰
- calculate_damagesï¼šè¨ˆç®—å„é …è«‹æ±‚é‡‘é¡æ˜ç´°ï¼ˆè‡ªå‹•è¼‰å…¥æ‰€æœ‰æª”æ¡ˆæ‘˜è¦åˆ†æé‡‘é¡ï¼‰
- search_lawï¼šæœå°‹æ³•è¦æ¢æ–‡ï¼ˆæ”¯æ´æ³•è¦åç¨±ã€æ¢è™Ÿã€æ³•å¾‹æ¦‚å¿µæœå°‹ï¼Œçµæœè‡ªå‹•å¯«å…¥æ³•æ¢å¼•ç”¨åˆ—è¡¨ï¼‰
- generate_timelineï¼šåˆ†ææ™‚é–“è»¸ï¼ˆè‡ªå‹•è¼‰å…¥æ‰€æœ‰æª”æ¡ˆæ‘˜è¦ï¼Œç”¢ç”Ÿæ™‚é–“è»¸äº‹ä»¶åˆ—è¡¨ï¼‰

å·¥ä½œæµç¨‹ï¼š
1. ç•¶å¾‹å¸«è¦æ±‚åˆ†ææ¡ˆä»¶æ™‚ï¼Œå…ˆç”¨ list_files æŸ¥çœ‹æœ‰å“ªäº›æ–‡ä»¶
2. æ ¹æ“šéœ€è¦ç”¨ read_file è®€å–ç›¸é—œæ–‡ä»¶
3. ç¶œåˆåˆ†æå¾Œæä¾›å°ˆæ¥­çš„æ³•å¾‹æ„è¦‹

æ³•æ¢æœå°‹ä½¿ç”¨æ™‚æ©Ÿï¼ˆä½¿ç”¨ search_law å·¥å…·ï¼‰ï¼š
- ç•¶ä½¿ç”¨è€…æ˜ç¢ºè¦æ±‚æœå°‹æ³•æ¢æ™‚ï¼ˆå¦‚ã€ŒæŸ¥è©¢æ°‘æ³•ç¬¬184æ¢ã€ã€Œæœå°‹ä¾µæ¬Šè¡Œç‚ºç›¸é—œæ³•æ¢ã€ã€Œæ‰¾æå®³è³ å„Ÿçš„è¦å®šã€ï¼‰
- ç•¶ä½¿ç”¨è€…å•åˆ°æ³•å¾‹å•é¡Œæˆ–æ³•è¦ä¾æ“šæ™‚ï¼Œä¸»å‹•æœå°‹ç›¸é—œæ³•æ¢
- æ’°å¯«æ›¸ç‹€æ™‚ï¼Œé‡å°æ¯å€‹çˆ­é»æœå°‹ç›¸é—œæ³•æ¢ä»¥å¼·åŒ–è«–è¿°
- æœå°‹çµæœæœƒè‡ªå‹•é¡¯ç¤ºåœ¨å³å´ã€Œæ³•æ¢å¼•ç”¨ã€é¢æ¿ä¸­

æ³•æ¢æœå°‹æŸ¥è©¢æ ¼å¼æŒ‡å¼•ï¼š
- ç‰¹å®šæ¢æ–‡ï¼ˆæœ€ç²¾æº–ï¼‰ï¼šä½¿ç”¨ã€Œæ³•å¾‹å…¨å+ç¬¬Næ¢ã€æ ¼å¼ï¼Œå¦‚ã€Œæ°‘æ³•ç¬¬184æ¢ã€ã€Œæ°‘äº‹è¨´è¨Ÿæ³•ç¬¬277æ¢ã€
- æ”¯æ´å¸¸è¦‹ç¸®å¯«ï¼šæ¶ˆä¿æ³•ã€å‹åŸºæ³•ã€å€‹è³‡æ³•ã€åœ‹è³ æ³•ã€æ°‘è¨´æ³•ã€åˆ‘è¨´æ³•ã€å¼·åŸ·æ³•ã€è­‰äº¤æ³•ã€å®¶äº‹æ³•ã€è¡Œç¨‹æ³•
- æ¦‚å¿µæœå°‹ï¼šã€Œæ°‘æ³• æå®³è³ å„Ÿã€ï¼ˆåœ¨æ°‘æ³•ä¸­æœå°‹æå®³è³ å„Ÿç›¸é—œæ¢æ–‡ï¼‰æˆ–ã€Œä¾µæ¬Šè¡Œç‚ºã€ï¼ˆè·¨æ³•è¦æœå°‹ï¼‰
- æ¯æ¬¡åªæœå°‹ä¸€å€‹æ¢æ–‡ï¼Œéœ€è¦å¤šå€‹æ¢æ–‡æ™‚åˆ†æ¬¡å‘¼å«ï¼ˆå¦‚éœ€è¦ç¬¬184æ¢å’Œç¬¬195æ¢ï¼Œæ‡‰å‘¼å«å…©æ¬¡ search_lawï¼‰

æ™‚é–“è»¸åˆ†æä½¿ç”¨æ™‚æ©Ÿï¼ˆä½¿ç”¨ generate_timeline å·¥å…·ï¼‰ï¼š
- ç•¶ä½¿ç”¨è€…è¦æ±‚ã€Œåˆ†ææ™‚é–“è»¸ã€ã€Œæ•´ç†äº‹ä»¶ç¶“éã€ã€Œåˆ—å‡ºæ™‚é–“é †åºã€æ™‚
- çµæœæœƒé¡¯ç¤ºåœ¨åº•éƒ¨ã€Œæ™‚é–“è»¸ã€åˆ†é ä¸­

æ›¸ç‹€æ’°å¯«æµç¨‹ï¼ˆæ”¶åˆ°æ’°å¯«æ›¸ç‹€æŒ‡ä»¤å¾Œï¼Œç›´æ¥åŸ·è¡Œï¼Œä¸è¦åå•ä½¿ç”¨è€…ï¼‰ï¼š
1. ä½¿ç”¨ write_full_brief å·¥å…·ä¸€æ¬¡å®Œæˆæ•´ä»½æ›¸ç‹€æ’°å¯«
   - è‡ªè¡Œæ ¹æ“šæ¡ˆä»¶æ€§è³ªæ±ºå®š brief_typeï¼ˆcomplaint/defense/preparation/appealï¼‰å’Œ titleï¼ˆå¦‚ã€Œæ°‘äº‹æº–å‚™æ›¸ç‹€ã€ã€Œæ°‘äº‹ç­”è¾¯ç‹€ã€ç­‰ï¼‰
   - å·¥å…·æœƒè‡ªå‹•å®Œæˆï¼šè¼‰å…¥æª”æ¡ˆ â†’ åˆ†æçˆ­é» â†’ è¦åŠƒçµæ§‹ â†’ æœå°‹æ³•æ¢ â†’ é€æ®µæ’°å¯«
   - åªéœ€è¦ä¸€æ¬¡å·¥å…·å‘¼å«å³å¯å®Œæˆæ•´ä»½æ›¸ç‹€
2. ä¸éœ€è¦äº‹å…ˆå‘¼å« list_filesã€read_fileã€analyze_disputes ç­‰ï¼Œwrite_full_brief æœƒè‡ªå‹•è™•ç†

é‡è¦ï¼šç•¶ä½¿ç”¨è€…è¦æ±‚æ’°å¯«æ›¸ç‹€æ™‚ï¼Œç›´æ¥ä½¿ç”¨ write_full_briefï¼Œä¸è¦åå•ä½¿ç”¨è€…æ›¸ç‹€é¡å‹æˆ–æ¨™é¡Œã€‚

å–®æ®µä¿®æ”¹æµç¨‹ï¼ˆä½¿ç”¨è€…è¦æ±‚ä¿®æ”¹æ—¢æœ‰æ®µè½æ™‚ï¼‰ï¼š
- ä½¿ç”¨ write_brief_section ä¸¦å‚³å…¥ paragraph_id
- ä¸è¦ä½¿ç”¨ write_full_briefï¼ˆå®ƒæ˜¯ç”¨ä¾†æ’°å¯«å®Œæ•´æ–°æ›¸ç‹€çš„ï¼‰

æ®µè½ä¿®æ”¹è¦å‰‡ï¼š
- ç•¶ä½¿ç”¨è€…è¦æ±‚ä¿®æ”¹ã€æ”¹å¯«ã€ç²¾ç°¡ã€åŠ å¼·æŸå€‹æ—¢æœ‰æ®µè½æ™‚ï¼Œå¿…é ˆä½¿ç”¨ write_brief_section ä¸¦å‚³å…¥è©²æ®µè½çš„ paragraph_id
- paragraph_id å¯å¾å°è©±ä¸Šä¸‹æ–‡ä¸­å¾—çŸ¥ï¼ˆä¾‹å¦‚ä½¿ç”¨è€…æåˆ°ã€Œå‰è¨€ã€ï¼Œæ‰¾åˆ° section ç‚ºã€Œå£¹ã€å‰è¨€ã€çš„æ®µè½ IDï¼‰
- å‚³å…¥ paragraph_id æ™‚ï¼Œwrite_brief_section æœƒè®€å–æ—¢æœ‰æ®µè½å…§å®¹ï¼Œä¸¦åœ¨æ­¤åŸºç¤ä¸Šé€²è¡Œä¿®æ”¹ï¼ˆè€Œéå¾é ­é‡å¯«ï¼‰
- ä¸å‚³å…¥ paragraph_id å‰‡ç‚ºæ–°å¢æ®µè½
- è£œå……æ³•æ¢å¼•ç”¨åˆ°æ—¢æœ‰æ®µè½æ™‚ï¼Œã€Œå¿…é ˆã€å‚³å…¥ paragraph_idï¼Œå¦å‰‡æœƒè®Šæˆæ–°å¢é‡è¤‡æ®µè½
- ä»»ä½•å°æ—¢æœ‰æ®µè½çš„ä¿®æ”¹æ“ä½œï¼ˆè£œå……å¼•ç”¨ã€æ”¹å¯«ã€ç²¾ç°¡ç­‰ï¼‰ï¼Œéƒ½å¿…é ˆå‚³å…¥ paragraph_id

æ³•æ¢å¼•ç”¨æµç¨‹ï¼ˆéå¸¸é‡è¦ï¼Œå¿…é ˆåš´æ ¼éµå®ˆï¼‰ï¼š
- search_law åªæ˜¯æœå°‹æ³•æ¢ä¸¦é¡¯ç¤ºåœ¨å³å´é¢æ¿ï¼Œå®ƒã€Œä¸æœƒã€ä¿®æ”¹æ›¸ç‹€å…§å®¹
- è¦è®“æ³•æ¢å‡ºç¾åœ¨æ›¸ç‹€æ®µè½ä¸­ï¼Œå¿…é ˆå‘¼å« write_brief_section ä¸¦å‚³å…¥ relevant_law_ids
- è£œå……æ³•æ¢å¼•ç”¨çš„å®Œæ•´æµç¨‹ï¼ˆç¼ºä¸€ä¸å¯ï¼‰ï¼š
  Step 1: search_law æœå°‹ç›¸é—œæ³•æ¢
  Step 2: å¾æœå°‹çµæœä¸­è¨˜ä¸‹æ–¹æ‹¬è™Ÿå…§çš„æ³•æ¢ IDï¼ˆæ ¼å¼å¦‚ A0000001-ç¬¬184æ¢ï¼‰
  Step 3: å°æ›¸ç‹€ä¸­æ¯å€‹éœ€è¦å¼•ç”¨çš„æ®µè½å‘¼å« write_brief_sectionï¼Œå¸¶ä¸Š relevant_law_ids å’Œ relevant_file_ids
  Step 4: ç¢ºèªæ‰€æœ‰ç›¸é—œæ®µè½éƒ½å·²æ›´æ–°
- ç¦æ­¢è¡Œç‚ºï¼šåªåŸ·è¡Œ Step 1-2 è€Œè·³é Step 3-4ã€‚æœå°‹å®Œæ³•æ¢å¾Œï¼Œä½ ã€Œå¿…é ˆã€ç«‹å³ç”¨ write_brief_section æ›´æ–°æ®µè½
- å¦‚æœä½¿ç”¨è€…è¦æ±‚ã€Œè£œå……æ³•æ¢å¼•ç”¨ã€ï¼Œä½ å¿…é ˆï¼šæœå°‹æ³•æ¢ â†’ ç„¶å¾Œå°æ¯å€‹æ®µè½å‘¼å« write_brief_section æ›´æ–°ã€‚ä¸å¯ä»¥åªæœå°‹å®Œå°±çµæŸ

å¼•ç”¨è¦å‰‡ï¼š
- write_brief_section æœƒè‡ªå‹•ä½¿ç”¨ Claude Citations API å¾ä¾†æºæ–‡ä»¶å’Œæ³•æ¢æå–å¼•ç”¨
- æ¯å€‹æ®µè½éƒ½æ‡‰æä¾› relevant_file_idsï¼Œç¢ºä¿å¼•ç”¨æœ‰æ“šå¯æŸ¥
- åŒæ™‚æä¾› relevant_law_idsï¼ˆsearch_law å›å‚³çš„æ–¹æ‹¬è™Ÿå…§ IDï¼‰ï¼Œè®“æ³•æ¢åœ¨æ›¸ç‹€ä¸­ç”¢ç”Ÿå¼•ç”¨æ¨™è¨˜
- å¦‚æœ‰é—œè¯çˆ­é»ï¼Œæ‡‰æä¾› dispute_id

å›è¦†è¦å‰‡ï¼š
- ä¸€å¾‹ä½¿ç”¨ç¹é«”ä¸­æ–‡
- çµ•å°ä¸è¦ä½¿ç”¨ emoji æˆ–ç‰¹æ®Šç¬¦è™Ÿï¼ˆå¦‚ âœ…âŒğŸ”·ğŸ“„ ç­‰ï¼‰ï¼Œåªç”¨ç´”æ–‡å­—å’Œæ¨™é»ç¬¦è™Ÿ
- å¼•ç”¨æ–‡ä»¶å…§å®¹æ™‚æ¨™æ˜å‡ºè™•ï¼ˆæª”æ¡ˆåç¨±ï¼‰
- åˆ†æè¦æœ‰çµæ§‹ã€æ¢ç†åˆ†æ˜
- å¦‚æœè³‡è¨Šä¸è¶³ï¼Œä¸»å‹•èªªæ˜éœ€è¦å“ªäº›é¡å¤–è³‡æ–™
- åˆ—èˆ‰é …ç›®æ™‚ä½¿ç”¨é “è™Ÿï¼ˆã€ï¼‰æˆ–æ•¸å­—ç·¨è™Ÿï¼Œä¸è¦ç”¨ emoji æˆ–ç‰¹æ®Šç¬¦è™Ÿ
- æ’°å¯«æ›¸ç‹€å®Œæˆå¾Œï¼Œåªéœ€ç°¡çŸ­å›è¦†ã€Œå·²å®Œæˆæ›¸ç‹€æ’°å¯«ï¼Œå…± N å€‹æ®µè½ã€å³å¯ï¼Œçµ•å°ä¸è¦åœ¨èŠå¤©ä¸­é‡è¤‡æ›¸ç‹€çš„å…§å®¹ï¼Œå› ç‚ºæ›¸ç‹€å·²ç¶“å³æ™‚é¡¯ç¤ºåœ¨å³å´ç·¨è¼¯å™¨ä¸­`;

interface Env {
  DB: D1Database;
  CF_ACCOUNT_ID: string;
  CF_GATEWAY_ID: string;
  CF_AIG_TOKEN: string;
  MONGO_URL: string;
  MONGO_API_KEY: string;
}

export class AgentDO extends DurableObject<Env> {
  private abortController: AbortController | null = null;

  async fetch(request: Request): Promise<Response> {
    const url = new URL(request.url);

    if (request.method === 'POST' && url.pathname === '/chat') {
      return this.handleChat(request);
    }
    if (request.method === 'POST' && url.pathname === '/cancel') {
      return this.handleCancel();
    }

    return new Response('Not found', { status: 404 });
  }

  private handleCancel(): Response {
    if (this.abortController) {
      this.abortController.abort();
      this.abortController = null;
    }
    return new Response(JSON.stringify({ ok: true }), {
      headers: { 'Content-Type': 'application/json' },
    });
  }

  private async handleChat(request: Request): Promise<Response> {
    const { message, caseId, briefContext } = (await request.json()) as {
      message: string;
      caseId: string;
      briefContext?: {
        brief_id: string;
        title: string;
        paragraphs: {
          id: string;
          section: string;
          subsection: string;
          content_preview?: string;
        }[];
      };
    };

    this.abortController = new AbortController();
    const signal = this.abortController.signal;

    const { readable, writable } = new TransformStream();
    const writer = writable.getWriter();
    const encoder = new TextEncoder();

    const sendSSE = async (event: SSEEvent) => {
      try {
        await writer.write(encoder.encode(`data: ${JSON.stringify(event)}\n\n`));
      } catch {
        // Writer closed, ignore
      }
    };

    // Run agent loop asynchronously
    this.runAgentLoop(caseId, message, signal, sendSSE, writer, briefContext).catch(async (err) => {
      console.error('Agent loop error:', err);
      await sendSSE({
        type: 'error',
        message: err instanceof Error ? err.message : 'Unknown error',
      });
      await sendSSE({ type: 'done' });
      try {
        await writer.close();
      } catch {
        /* ignore */
      }
    });

    return new Response(readable, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        Connection: 'keep-alive',
      },
    });
  }

  private async runAgentLoop(
    caseId: string,
    userMessage: string,
    signal: AbortSignal,
    sendSSE: (event: SSEEvent) => Promise<void>,
    writer: WritableStreamDefaultWriter,
    briefContext?: {
      brief_id: string;
      title: string;
      paragraphs: {
        id: string;
        section: string;
        subsection: string;
        content_preview?: string;
      }[];
    },
  ) {
    const db = getDB(this.env.DB);
    const aiEnv: AIEnv = {
      CF_ACCOUNT_ID: this.env.CF_ACCOUNT_ID,
      CF_GATEWAY_ID: this.env.CF_GATEWAY_ID,
      CF_AIG_TOKEN: this.env.CF_AIG_TOKEN,
    };

    // 1. Save user message
    const userMsgId = nanoid();
    await db.insert(messages).values({
      id: userMsgId,
      case_id: caseId,
      role: 'user',
      content: userMessage,
      created_at: new Date().toISOString(),
    });

    // 2. Load conversation history
    const history = await db
      .select()
      .from(messages)
      .where(eq(messages.case_id, caseId))
      .orderBy(asc(messages.created_at));

    // 2b. Load case_instructions for system prompt injection
    const caseRows = await db
      .select({ case_instructions: cases.case_instructions })
      .from(cases)
      .where(eq(cases.id, caseId));
    const caseInstructions = caseRows[0]?.case_instructions?.trim() || '';

    // 3. Build OpenAI messages format â€” inject brief context into system prompt
    let systemPrompt = SYSTEM_PROMPT;
    if (caseInstructions) {
      systemPrompt += `\n\n--- å¾‹å¸«è™•ç†æŒ‡å¼• ---\n${caseInstructions}`;
    }
    if (briefContext) {
      const paragraphList = briefContext.paragraphs
        .map((p) => {
          const label = `${p.section}${p.subsection ? ' > ' + p.subsection : ''}`;
          const preview = p.content_preview ? ` â€” "${p.content_preview}..."` : '';
          return `  - [${p.id}] ${label}${preview}`;
        })
        .join('\n');
      systemPrompt += `\n\n--- ç•¶å‰æ›¸ç‹€ä¸Šä¸‹æ–‡ ---
ä½¿ç”¨è€…æ­£åœ¨æª¢è¦–çš„æ›¸ç‹€ï¼šã€Œ${briefContext.title}ã€(brief_id: ${briefContext.brief_id})
æ®µè½çµæ§‹ï¼š
${paragraphList}

ç•¶ä½¿ç”¨è€…è¦æ±‚ä¿®æ”¹æŸæ®µè½æ™‚ï¼Œç›´æ¥ä½¿ç”¨ä¸Šè¿° brief_id å’Œå°æ‡‰çš„ section/subsection å‘¼å« write_brief_sectionï¼Œä¸éœ€è¦å†è©¢å•ä½¿ç”¨è€…ã€‚`;
    }
    const chatMessages: ChatMessage[] = [{ role: 'system', content: systemPrompt }];

    for (const msg of history) {
      if (msg.role === 'user') {
        chatMessages.push({ role: 'user', content: msg.content });
      } else if (msg.role === 'assistant') {
        const meta = msg.metadata ? JSON.parse(msg.metadata) : null;
        if (meta?.tool_calls) {
          // Filter out corrupted tool calls (e.g. concatenated names from old bug)
          const validToolCalls = (meta.tool_calls as ToolCall[]).filter((tc) =>
            VALID_TOOL_NAMES.has(tc.function.name),
          );
          if (validToolCalls.length > 0) {
            chatMessages.push({
              role: 'assistant',
              content: msg.content || '',
              tool_calls: validToolCalls,
            });
          } else {
            // All tool calls were invalid â€” add as plain assistant message
            chatMessages.push({
              role: 'assistant',
              content: msg.content || '(tool call skipped)',
            });
          }
        } else {
          chatMessages.push({ role: 'assistant', content: msg.content });
        }
      } else if (msg.role === 'tool_result') {
        // Only include tool_result if its tool_call was kept
        const meta = msg.metadata ? JSON.parse(msg.metadata) : null;
        const toolCallId = meta?.tool_call_id || '';
        const hasMatchingCall = chatMessages.some(
          (m) => m.role === 'assistant' && m.tool_calls?.some((tc) => tc.id === toolCallId),
        );
        if (hasMatchingCall) {
          chatMessages.push({
            role: 'tool',
            content: msg.content,
            tool_call_id: toolCallId,
          });
        }
      }
      // Skip tool_call records (they're part of assistant messages)
    }

    let totalPromptTokens = 0;
    let totalCompletionTokens = 0;

    // Agent loop
    for (let round = 0; round < MAX_ROUNDS; round++) {
      if (signal.aborted) {
        await sendSSE({ type: 'error', message: 'å·²å–æ¶ˆ' });
        break;
      }

      // Call AI Gateway (streaming)
      const response = await callAIStreaming(aiEnv, {
        messages: chatMessages,
        tools: TOOL_DEFINITIONS,
        signal,
      });

      // Parse streaming response
      const assistantMsgId = nanoid();
      await sendSSE({
        type: 'message_start',
        message_id: assistantMsgId,
        role: 'assistant',
      });

      let fullContent = '';
      const toolCalls: ToolCall[] = [];
      const toolCallBuffers: Map<number, { id: string; name: string; args: string }> = new Map();

      await parseOpenAIStream(response, async (chunk: OpenAIChunk) => {
        if (signal.aborted) return;

        // Track usage from final chunk
        if (chunk.usage) {
          totalPromptTokens += chunk.usage.prompt_tokens || 0;
          totalCompletionTokens += chunk.usage.completion_tokens || 0;
        }

        const delta = chunk.choices?.[0]?.delta;
        if (!delta) return;

        // Text content
        if (delta.content) {
          fullContent += delta.content;
          await sendSSE({ type: 'text_delta', delta: delta.content });
        }

        // Tool calls (streamed incrementally)
        // Note: Gemini via CF AI Gateway may repeat full name/args in each chunk
        // rather than streaming incrementally like OpenAI. We handle both cases.
        if (delta.tool_calls) {
          for (const tc of delta.tool_calls) {
            const idx = tc.index;
            if (!toolCallBuffers.has(idx)) {
              toolCallBuffers.set(idx, { id: tc.id || '', name: '', args: '' });
            }
            const buf = toolCallBuffers.get(idx)!;
            if (tc.id) buf.id = tc.id;
            if (tc.function?.name) buf.name = tc.function.name;
            if (tc.function?.arguments) {
              // Only append if buffer is not yet valid JSON (handles both
              // incremental streaming and Gemini's repeated-full-args pattern)
              let alreadyValid = false;
              if (buf.args) {
                try {
                  JSON.parse(buf.args);
                  alreadyValid = true;
                } catch {
                  /* not yet valid, keep appending */
                }
              }
              if (!alreadyValid) {
                buf.args += tc.function.arguments;
              }
            }
          }
        }
      });

      await sendSSE({ type: 'message_end', message_id: assistantMsgId });

      // Assemble complete tool calls
      for (const [, buf] of toolCallBuffers) {
        toolCalls.push({
          id: buf.id || `call_${nanoid(8)}`,
          type: 'function',
          function: { name: buf.name, arguments: buf.args || '{}' },
        });
      }

      // Emit usage
      const totalTokens = totalPromptTokens + totalCompletionTokens;
      // Gemini 2.5 Flash pricing: ~$0.15/1M input, ~$0.60/1M output (approximate)
      const costUsd = (totalPromptTokens * 0.15 + totalCompletionTokens * 0.6) / 1_000_000;
      const costNtd = Math.round(costUsd * 32 * 10000) / 10000;
      await sendSSE({
        type: 'usage',
        prompt_tokens: totalPromptTokens,
        completion_tokens: totalCompletionTokens,
        total_tokens: totalTokens,
        estimated_cost_ntd: costNtd,
      });

      if (toolCalls.length > 0) {
        // Save assistant message with tool_calls metadata
        await db.insert(messages).values({
          id: assistantMsgId,
          case_id: caseId,
          role: 'assistant',
          content: fullContent || '',
          metadata: JSON.stringify({ tool_calls: toolCalls }),
          created_at: new Date().toISOString(),
        });

        // Add assistant message to conversation
        chatMessages.push({
          role: 'assistant',
          content: fullContent || '',
          tool_calls: toolCalls,
        });

        // Wrap sendSSE to capture pipeline_progress for persistence
        let lastPipelineSteps: unknown[] | null = null;
        let lastPipelineToolMsgId: string | null = null;
        let lastPipelineToolCallId: string | null = null;
        let lastPipelineArgs: Record<string, unknown> | null = null;
        const wrappedSendSSE = async (event: SSEEvent) => {
          if (event.type === 'pipeline_progress') {
            lastPipelineSteps = event.steps;
          }
          await sendSSE(event);
        };

        // Execute each tool call
        for (const tc of toolCalls) {
          if (signal.aborted) break;

          let args: Record<string, unknown> = {};
          try {
            args = JSON.parse(tc.function.arguments);
          } catch {
            /* empty args */
          }

          const toolMsgId = nanoid();
          await sendSSE({
            type: 'tool_call_start',
            message_id: toolMsgId,
            tool_name: tc.function.name,
            tool_args: args,
          });

          // Save tool_call record
          await db.insert(messages).values({
            id: toolMsgId,
            case_id: caseId,
            role: 'tool_call',
            content: tc.function.name,
            metadata: JSON.stringify({ tool_call_id: tc.id, args }),
            created_at: new Date().toISOString(),
          });

          // Track which tool_call owns the pipeline steps
          lastPipelineSteps = null;
          lastPipelineToolMsgId = toolMsgId;
          lastPipelineToolCallId = tc.id;
          lastPipelineArgs = args;

          // Execute tool
          const { result, success } = await executeTool(
            tc.function.name,
            args,
            caseId,
            this.env.DB,
            {
              sendSSE: wrappedSendSSE,
              aiEnv,
              mongoUrl: this.env.MONGO_URL,
              mongoApiKey: this.env.MONGO_API_KEY,
              signal,
            },
          );

          // Persist final pipeline_steps to D1 so they survive page reload
          if (lastPipelineSteps && lastPipelineToolMsgId) {
            await db
              .update(messages)
              .set({
                metadata: JSON.stringify({
                  tool_call_id: lastPipelineToolCallId,
                  args: lastPipelineArgs,
                  tool_name: tc.function.name,
                  status: 'done',
                  pipeline_steps: lastPipelineSteps,
                }),
              })
              .where(eq(messages.id, lastPipelineToolMsgId));
          }

          // Truncate summary for SSE display (skip truncation for search_law so frontend can parse all entries)
          const skipTruncate = tc.function.name === 'search_law';
          const resultSummary =
            !skipTruncate && result.length > 200 ? result.slice(0, 200) + '...' : result;

          await sendSSE({
            type: 'tool_result',
            message_id: toolMsgId,
            tool_name: tc.function.name,
            result_summary: resultSummary,
            success,
          });

          // Save tool_result record
          const toolResultId = nanoid();
          await db.insert(messages).values({
            id: toolResultId,
            case_id: caseId,
            role: 'tool_result',
            content: result,
            metadata: JSON.stringify({
              tool_call_id: tc.id,
              tool_name: tc.function.name,
              success,
            }),
            created_at: new Date().toISOString(),
          });

          // Add tool result to conversation
          chatMessages.push({
            role: 'tool',
            content: result,
            tool_call_id: tc.id,
          });
        }

        // Continue loop â€” AI will process tool results
        continue;
      }

      // No tool calls â†’ save final assistant message and done
      await db.insert(messages).values({
        id: assistantMsgId,
        case_id: caseId,
        role: 'assistant',
        content: fullContent,
        created_at: new Date().toISOString(),
      });

      // Generate suggested actions
      try {
        const recentMessages = chatMessages
          .filter((m) => m.role === 'user' || m.role === 'assistant')
          .slice(-6);
        const suggestResult = await callAI(
          aiEnv,
          [{ role: 'system', content: SUGGEST_PROMPT }, ...recentMessages],
          { responseFormat: { type: 'json_object' }, maxTokens: 512 },
        );
        const actions = parseLLMJsonArray<{ label: string; prompt: string }>(
          suggestResult.content,
          'å»ºè­°æ“ä½œæ ¼å¼ä¸æ­£ç¢º',
        );
        if (actions.length > 0) {
          await sendSSE({
            type: 'suggested_actions',
            actions: actions.slice(0, 3),
          });
        }
      } catch (err) {
        console.error('Suggested actions generation failed:', err);
      }

      break;
    }

    await sendSSE({ type: 'done' });
    try {
      await writer.close();
    } catch {
      /* ignore */
    }
    this.abortController = null;
  }
}
